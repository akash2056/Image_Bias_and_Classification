
# Freeze all layers except the last 4 layers
---------------------------------------------

Epoch 1/200
/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
78/78 ━━━━━━━━━━━━━━━━━━━━ 37s 382ms/step - accuracy: 0.4949 - loss: 1.8366 - val_accuracy: 0.4984 - val_loss: 2.0419 - learning_rate: 0.0010
Epoch 2/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 333ms/step - accuracy: 0.5093 - loss: 1.3168 - val_accuracy: 0.5468 - val_loss: 1.3862 - learning_rate: 0.0010
Epoch 3/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 335ms/step - accuracy: 0.6040 - loss: 1.0542 - val_accuracy: 0.6774 - val_loss: 0.8985 - learning_rate: 0.0010
Epoch 4/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 328ms/step - accuracy: 0.6549 - loss: 0.8870 - val_accuracy: 0.6161 - val_loss: 0.9430 - learning_rate: 0.0010
Epoch 5/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 332ms/step - accuracy: 0.7021 - loss: 0.7740 - val_accuracy: 0.6984 - val_loss: 0.7641 - learning_rate: 0.0010
Epoch 6/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 331ms/step - accuracy: 0.6959 - loss: 0.7061 - val_accuracy: 0.6952 - val_loss: 0.7669 - learning_rate: 0.0010
Epoch 7/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 328ms/step - accuracy: 0.7151 - loss: 0.6334 - val_accuracy: 0.5210 - val_loss: 2.0070 - learning_rate: 0.0010
Epoch 8/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 329ms/step - accuracy: 0.7154 - loss: 0.5967 - val_accuracy: 0.5532 - val_loss: 1.7043 - learning_rate: 0.0010
Epoch 9/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 329ms/step - accuracy: 0.7280 - loss: 0.5546 - val_accuracy: 0.6548 - val_loss: 0.7392 - learning_rate: 0.0010
Epoch 10/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 332ms/step - accuracy: 0.7316 - loss: 0.5698 - val_accuracy: 0.7081 - val_loss: 0.7351 - learning_rate: 0.0010
Epoch 11/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 329ms/step - accuracy: 0.7311 - loss: 0.4596 - val_accuracy: 0.7177 - val_loss: 0.6768 - learning_rate: 0.0010
Epoch 12/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 325ms/step - accuracy: 0.7273 - loss: 0.4112 - val_accuracy: 0.7097 - val_loss: 0.7690 - learning_rate: 0.0010
Epoch 13/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 329ms/step - accuracy: 0.7427 - loss: 0.4989 - val_accuracy: 0.6548 - val_loss: 1.1183 - learning_rate: 0.0010
Epoch 14/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 326ms/step - accuracy: 0.7040 - loss: 0.3936 - val_accuracy: 0.6645 - val_loss: 1.0388 - learning_rate: 0.0010
Epoch 15/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 326ms/step - accuracy: 0.6970 - loss: 0.2912 - val_accuracy: 0.6274 - val_loss: 1.4142 - learning_rate: 0.0010
Epoch 16/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 333ms/step - accuracy: 0.7414 - loss: 0.3125 - val_accuracy: 0.5177 - val_loss: 3.8101 - learning_rate: 0.0010
Epoch 17/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 333ms/step - accuracy: 0.7024 - loss: 0.1557 - val_accuracy: 0.7355 - val_loss: 0.7530 - learning_rate: 5.0000e-04
Epoch 18/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 332ms/step - accuracy: 0.7423 - loss: 0.2667 - val_accuracy: 0.7387 - val_loss: 0.7070 - learning_rate: 5.0000e-04
Epoch 19/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 334ms/step - accuracy: 0.7508 - loss: -0.0723 - val_accuracy: 0.6048 - val_loss: 1.5685 - learning_rate: 5.0000e-04
Epoch 20/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 330ms/step - accuracy: 0.7380 - loss: -0.1251 - val_accuracy: 0.5629 - val_loss: 3.8725 - learning_rate: 5.0000e-04
Epoch 21/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 28s 327ms/step - accuracy: 0.7410 - loss: 0.4727 - val_accuracy: 0.6887 - val_loss: 0.7358 - learning_rate: 5.0000e-04

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# Freeze all layers except the last 5 layers
--------------------------------------------

Epoch 1/200
/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1732118985.714247      97 service.cc:145] XLA service 0x79d718007640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1732118985.714308      97 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
I0000 00:00:1732118985.714311      97 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
 1/78 ━━━━━━━━━━━━━━━━━━━━ 27:52 22s/step - accuracy: 0.5000 - loss: 1.9045
I0000 00:00:1732119002.519955      97 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
78/78 ━━━━━━━━━━━━━━━━━━━━ 66s 574ms/step - accuracy: 0.5046 - loss: 1.8045 - val_accuracy: 0.5339 - val_loss: 1.4757 - learning_rate: 0.0010
Epoch 2/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 26s 311ms/step - accuracy: 0.5636 - loss: 1.2149 - val_accuracy: 0.5016 - val_loss: 1.6876 - learning_rate: 0.0010
Epoch 3/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 313ms/step - accuracy: 0.6273 - loss: 0.9879 - val_accuracy: 0.5855 - val_loss: 1.0256 - learning_rate: 0.0010
Epoch 4/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 317ms/step - accuracy: 0.6609 - loss: 0.8431 - val_accuracy: 0.5290 - val_loss: 1.4755 - learning_rate: 0.0010
Epoch 5/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 323ms/step - accuracy: 0.6586 - loss: 0.7880 - val_accuracy: 0.5097 - val_loss: 2.0913 - learning_rate: 0.0010
Epoch 6/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 321ms/step - accuracy: 0.6842 - loss: 0.6932 - val_accuracy: 0.5274 - val_loss: 1.7808 - learning_rate: 0.0010
Epoch 7/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 321ms/step - accuracy: 0.7194 - loss: 0.6231 - val_accuracy: 0.5065 - val_loss: 1.9223 - learning_rate: 0.0010
Epoch 8/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 323ms/step - accuracy: 0.7002 - loss: 0.6076 - val_accuracy: 0.6081 - val_loss: 1.2112 - learning_rate: 0.0010
Epoch 9/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 319ms/step - accuracy: 0.7167 - loss: 0.4924 - val_accuracy: 0.5274 - val_loss: 1.7603 - learning_rate: 5.0000e-04
Epoch 10/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 321ms/step - accuracy: 0.7661 - loss: 0.4047 - val_accuracy: 0.6935 - val_loss: 0.6647 - learning_rate: 5.0000e-04
Epoch 11/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 320ms/step - accuracy: 0.7389 - loss: 0.3050 - val_accuracy: 0.7000 - val_loss: 0.6549 - learning_rate: 5.0000e-04
Epoch 12/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 316ms/step - accuracy: 0.7547 - loss: 0.2417 - val_accuracy: 0.5210 - val_loss: 2.3790 - learning_rate: 5.0000e-04
Epoch 13/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 323ms/step - accuracy: 0.7598 - loss: 0.2531 - val_accuracy: 0.4968 - val_loss: 565.9922 - learning_rate: 5.0000e-04
Epoch 14/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 320ms/step - accuracy: 0.7495 - loss: 0.4089 - val_accuracy: 0.5839 - val_loss: 2.1772 - learning_rate: 5.0000e-04
Epoch 15/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 316ms/step - accuracy: 0.7199 - loss: 0.4293 - val_accuracy: 0.4968 - val_loss: 7.5262 - learning_rate: 5.0000e-04
Epoch 16/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 322ms/step - accuracy: 0.6194 - loss: 0.7321 - val_accuracy: 0.5210 - val_loss: 5.4244 - learning_rate: 5.0000e-04
Epoch 17/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 319ms/step - accuracy: 0.6913 - loss: 0.6066 - val_accuracy: 0.7129 - val_loss: 0.7228 - learning_rate: 2.5000e-04
Epoch 18/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 318ms/step - accuracy: 0.7388 - loss: 0.4415 - val_accuracy: 0.6516 - val_loss: 0.9007 - learning_rate: 2.5000e-04
Epoch 19/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 317ms/step - accuracy: 0.7347 - loss: 0.5356 - val_accuracy: 0.6048 - val_loss: 1.3820 - learning_rate: 2.5000e-04
Epoch 20/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 322ms/step - accuracy: 0.7312 - loss: 0.3946 - val_accuracy: 0.5113 - val_loss: 1.0965 - learning_rate: 2.5000e-04
Epoch 21/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 323ms/step - accuracy: 0.7255 - loss: 0.4276 - val_accuracy: 0.7274 - val_loss: 0.6377 - learning_rate: 2.5000e-04
Epoch 22/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 318ms/step - accuracy: 0.7342 - loss: 0.0649 - val_accuracy: 0.7339 - val_loss: 0.6270 - learning_rate: 2.5000e-04
Epoch 23/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 318ms/step - accuracy: 0.7318 - loss: 0.2774 - val_accuracy: 0.6661 - val_loss: 0.7577 - learning_rate: 2.5000e-04
Epoch 24/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 318ms/step - accuracy: 0.7344 - loss: 0.1395 - val_accuracy: 0.6726 - val_loss: 0.6684 - learning_rate: 2.5000e-04
Epoch 25/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 316ms/step - accuracy: 0.7446 - loss: -0.2242 - val_accuracy: 0.6371 - val_loss: 0.8918 - learning_rate: 2.5000e-04
Epoch 26/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 318ms/step - accuracy: 0.7600 - loss: 0.1740 - val_accuracy: 0.6452 - val_loss: 0.7898 - learning_rate: 2.5000e-04
Epoch 27/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 319ms/step - accuracy: 0.7451 - loss: -0.0811 - val_accuracy: 0.6468 - val_loss: 0.9857 - learning_rate: 2.5000e-04
Epoch 28/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 320ms/step - accuracy: 0.7544 - loss: 0.0258 - val_accuracy: 0.4968 - val_loss: 16.5744 - learning_rate: 1.2500e-04
Epoch 29/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 319ms/step - accuracy: 0.7261 - loss: 0.4038 - val_accuracy: 0.6694 - val_loss: 0.8897 - learning_rate: 1.2500e-04
Epoch 30/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 321ms/step - accuracy: 0.7684 - loss: 0.1210 - val_accuracy: 0.7419 - val_loss: 0.7151 - learning_rate: 1.2500e-04
Epoch 31/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 316ms/step - accuracy: 0.7746 - loss: -0.3702 - val_accuracy: 0.7161 - val_loss: 0.7700 - learning_rate: 1.2500e-04
Epoch 32/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 314ms/step - accuracy: 0.7741 - loss: -0.1831 - val_accuracy: 0.7290 - val_loss: 0.7129 - learning_rate: 1.2500e-04

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# Freeze all layers except the last 6 layers
---------------------------------------------
Epoch 1/200
/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1732133002.440021      99 service.cc:145] XLA service 0x7d735c011a70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1732133002.440090      99 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
I0000 00:00:1732133002.440095      99 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
 1/78 ━━━━━━━━━━━━━━━━━━━━ 30:48 24s/step - accuracy: 0.4688 - loss: 2.1755
I0000 00:00:1732133021.358519      99 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
78/78 ━━━━━━━━━━━━━━━━━━━━ 69s 578ms/step - accuracy: 0.4886 - loss: 1.7723 - val_accuracy: 0.4968 - val_loss: 3.1201 - learning_rate: 0.0010
Epoch 2/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 314ms/step - accuracy: 0.5309 - loss: 1.1625 - val_accuracy: 0.4968 - val_loss: 2.1837 - learning_rate: 0.0010
Epoch 3/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 313ms/step - accuracy: 0.5533 - loss: 0.9872 - val_accuracy: 0.5048 - val_loss: 2.3211 - learning_rate: 0.0010
Epoch 4/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 320ms/step - accuracy: 0.6078 - loss: 0.8770 - val_accuracy: 0.5032 - val_loss: 1.7102 - learning_rate: 0.0010
Epoch 5/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 319ms/step - accuracy: 0.6047 - loss: 0.8102 - val_accuracy: 0.6468 - val_loss: 0.7734 - learning_rate: 0.0010
Epoch 6/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 319ms/step - accuracy: 0.6493 - loss: 0.7460 - val_accuracy: 0.5016 - val_loss: 1.1950 - learning_rate: 0.0010
Epoch 7/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 315ms/step - accuracy: 0.6514 - loss: 0.7247 - val_accuracy: 0.5097 - val_loss: 2.0798 - learning_rate: 0.0010
Epoch 8/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 321ms/step - accuracy: 0.6619 - loss: 0.6614 - val_accuracy: 0.6306 - val_loss: 0.7693 - learning_rate: 0.0010
Epoch 9/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 318ms/step - accuracy: 0.7046 - loss: 0.6169 - val_accuracy: 0.5242 - val_loss: 1.7116 - learning_rate: 0.0010
Epoch 10/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 317ms/step - accuracy: 0.6594 - loss: 0.6847 - val_accuracy: 0.6984 - val_loss: 0.6645 - learning_rate: 0.0010
Epoch 11/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 315ms/step - accuracy: 0.6985 - loss: 0.6117 - val_accuracy: 0.4968 - val_loss: 6.1246 - learning_rate: 0.0010
Epoch 12/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 315ms/step - accuracy: 0.7106 - loss: 0.6481 - val_accuracy: 0.7226 - val_loss: 0.6835 - learning_rate: 0.0010
Epoch 13/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 314ms/step - accuracy: 0.7433 - loss: 0.5692 - val_accuracy: 0.6806 - val_loss: 0.8971 - learning_rate: 0.0010
Epoch 14/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 318ms/step - accuracy: 0.7536 - loss: 0.5766 - val_accuracy: 0.5968 - val_loss: 2.2496 - learning_rate: 0.0010
Epoch 15/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 317ms/step - accuracy: 0.7255 - loss: 0.5467 - val_accuracy: 0.7194 - val_loss: 0.7171 - learning_rate: 0.0010
Epoch 16/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 315ms/step - accuracy: 0.7496 - loss: 0.4990 - val_accuracy: 0.6935 - val_loss: 0.7669 - learning_rate: 5.0000e-04
Epoch 17/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 26s 310ms/step - accuracy: 0.7775 - loss: 0.4309 - val_accuracy: 0.5661 - val_loss: 1.4191 - learning_rate: 5.0000e-04
Epoch 18/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 315ms/step - accuracy: 0.7346 - loss: 0.4056 - val_accuracy: 0.4968 - val_loss: 2.7051 - learning_rate: 5.0000e-04
Epoch 19/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 318ms/step - accuracy: 0.7517 - loss: 0.4387 - val_accuracy: 0.7194 - val_loss: 0.6014 - learning_rate: 5.0000e-04
Epoch 20/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 317ms/step - accuracy: 0.7528 - loss: 0.3462 - val_accuracy: 0.5016 - val_loss: 2.0757 - learning_rate: 5.0000e-04
Epoch 21/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 323ms/step - accuracy: 0.7621 - loss: 0.2041 - val_accuracy: 0.6484 - val_loss: 0.9508 - learning_rate: 5.0000e-04
Epoch 22/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 317ms/step - accuracy: 0.7768 - loss: 0.1446 - val_accuracy: 0.7355 - val_loss: 0.6142 - learning_rate: 5.0000e-04
Epoch 23/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 315ms/step - accuracy: 0.7761 - loss: -0.0362 - val_accuracy: 0.6532 - val_loss: 0.8257 - learning_rate: 5.0000e-04
Epoch 24/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 314ms/step - accuracy: 0.7582 - loss: -0.0519 - val_accuracy: 0.5145 - val_loss: 5.3085 - learning_rate: 5.0000e-04
Epoch 25/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 317ms/step - accuracy: 0.7079 - loss: 0.2902 - val_accuracy: 0.7242 - val_loss: 0.6255 - learning_rate: 2.5000e-04
Epoch 26/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 316ms/step - accuracy: 0.7509 - loss: -0.0679 - val_accuracy: 0.7226 - val_loss: 0.6681 - learning_rate: 2.5000e-04
Epoch 27/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 315ms/step - accuracy: 0.7905 - loss: 0.0079 - val_accuracy: 0.5645 - val_loss: 1.2788 - learning_rate: 2.5000e-04
Epoch 28/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 317ms/step - accuracy: 0.7568 - loss: -0.1260 - val_accuracy: 0.5968 - val_loss: 1.3740 - learning_rate: 2.5000e-04
Epoch 29/200
78/78 ━━━━━━━━━━━━━━━━━━━━ 27s 313ms/step - accuracy: 0.7846 - loss: -0.0401 - val_accuracy: 0.4968 - val_loss: 13.8723 - learning_rate: 2.5000e-04